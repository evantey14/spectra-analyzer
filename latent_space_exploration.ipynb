{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import corner\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from data import data_loader, toy_data\n",
    "import glow as model\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('font', family='serif')\n",
    "plt.rc('xtick', labelsize=8)\n",
    "plt.rc('ytick', labelsize=8)\n",
    "plt.rc('axes', labelsize=8)\n",
    "plt.rc('figure', autolayout=True, dpi=300)\n",
    "plt.rc('lines', linewidth=1)\n",
    "plt.rc('legend', fontsize=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class hps:\n",
    "    pass\n",
    "hps.n_levels = 10 # number of splits\n",
    "hps.depth = 3 # number of layers in revnet\n",
    "hps.width = 16 # channels in revnet layers\n",
    "hps.polyak_epochs = 1\n",
    "hps.beta1 = .9 # learning rate annealing factor\n",
    "hps.weight_decay = 1 # learning rate annealing factor\n",
    "hps.lr = .001 # base learning rate\n",
    "hps.n_data = 4000 # number of input spectra\n",
    "hps.batch_size = 50 # number of spectra in a batch\n",
    "hps.n_batches = int(hps.n_data / hps.batch_size)\n",
    "hps.n_bins = 2**12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.compat.v1.InteractiveSession()\n",
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_source = 'toy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_source == 'toy':\n",
    "    spectra, labels = toy_data.generate_spectra(hps.n_data, hps.n_bins)\n",
    "    labels = labels[:, 1:3] # ignore temperature and sigma (leaving A, mu)\n",
    "    input_stream, label_stream, initialize_stream = (\n",
    "        data_loader.create_loader_from_array(sess, hps.batch_size, spectra, labels)\n",
    "    )\n",
    "elif data_source == 'real':\n",
    "    input_stream, label_stream, initialize_stream = (\n",
    "        data_loader.create_loader_from_hdf5(sess, hps.batch_size, 'data/sample_short.h5')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "initialize_stream()\n",
    "spectra = sess.run(input_stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "for spectrum in spectra[:5]:\n",
    "    plt.plot(spectrum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#with tf.device(\"/device:GPU:0\"):\n",
    "m = model.model(sess, hps, input_stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.restore('models/model-200507-075409')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = np.random.randint(0, hps.batch_size)\n",
    "spectrum = spectra[i:i+1, :, :]\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_rep, intermediate_zs = m.encode(spectrum)\n",
    "reconstruction = m.decode(latent_rep)\n",
    "perfect_reconstruction = m.decode(latent_rep, intermediate_zs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feed_dict(z):\n",
    "    feed_dict = {m.z_placeholder: z}\n",
    "    for i in range(len(intermediate_zs)):\n",
    "        feed_dict[m.intermediate_z_placeholders[i]] = intermediate_zs[i]\n",
    "    return feed_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = (0, hps.n_bins)\n",
    "window = (int(hps.n_bins*.45), int(hps.n_bins*.55))\n",
    "#window = (12000, 14000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdas = np.linspace(0, 30000, 2**12) # in angstrom\n",
    "lambdas = lambdas[window[0]:window[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(np.linspace(0, 30000, 2**12), np.squeeze(spectrum), label='x')\n",
    "plt.plot(np.linspace(0, 30000, 2**12), np.squeeze(reconstruction), label='d(z)')\n",
    "plt.axvline(lambdas[0])\n",
    "plt.axvline(lambdas[-1])\n",
    "plt.xlabel('Wavelength $[\\AA]$')\n",
    "plt.ylabel('Normalized flux')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(lambdas, np.squeeze(spectrum)[window[0]:window[1]])\n",
    "plt.plot(lambdas, np.squeeze(reconstruction)[window[0]:window[1]])\n",
    "plt.xlabel('Wavelength $[\\AA]$')\n",
    "plt.ylabel('Normalized flux')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gaussian_kernel(size, mean, std):\n",
    "    d = tf.distributions.Normal(tf.cast(mean, tf.float32), tf.cast(std, tf.float32))\n",
    "    vals = d.prob(tf.range(start=-int(size/2), limit=int(size/2)+1, dtype=tf.float32))\n",
    "\n",
    "    kernel = vals[:, np.newaxis, np.newaxis]\n",
    "    return kernel / tf.reduce_sum(kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian_kernel = create_gaussian_kernel(51, 0, 25)\n",
    "derivative_kernel = tf.constant([[[-hps.n_bins / 2]], [[0]], [[hps.n_bins / 2]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoothed = tf.nn.conv1d(m.s_from_intermediate_zs, gaussian_kernel, padding=\"SAME\")\n",
    "first_derivative = tf.nn.conv1d(smoothed, derivative_kernel, padding=\"SAME\")\n",
    "smoothed_first_derivative = tf.nn.conv1d(first_derivative, gaussian_kernel, padding=\"SAME\")\n",
    "second_derivative = tf.nn.conv1d(smoothed_first_derivative, derivative_kernel, padding=\"SAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoothed_spectra = sess.run(smoothed, get_feed_dict(latent_rep))\n",
    "first_derivative_spectra = sess.run(first_derivative, get_feed_dict(latent_rep))\n",
    "second_derivative_spectra = sess.run(second_derivative, get_feed_dict(latent_rep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 2))\n",
    "plt.plot(np.squeeze(reconstruction))\n",
    "plt.plot(np.squeeze(smoothed_spectra))\n",
    "plt.plot(np.squeeze(first_derivative_spectra) / first_derivative_spectra.std())\n",
    "plt.plot(np.squeeze(second_derivative_spectra) / second_derivative_spectra.std())\n",
    "plt.axvline(window[0])\n",
    "plt.axvline(window[1])\n",
    "plt.ylim(-5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outside window\n",
    "left_squared_error = tf.reduce_sum((spectrum[:, :window[0]] - m.s_from_intermediate_zs[:, :window[0]])**2)\n",
    "right_squared_error = tf.reduce_sum((spectrum[:, window[1]:] - m.s_from_intermediate_zs[:, window[1]:])**2)\n",
    "outside_cost = left_squared_error + right_squared_error\n",
    "\n",
    "# inside window\n",
    "#inside_cost = tf.reduce_sum((spectrum[:, window[0]:window[1]] - m.decoded_spectra[:, window[0]:window[1]])**2)\n",
    "inside_cost = -tf.reduce_sum(second_derivative[:, window[0]:window[1]]**2)\n",
    "\n",
    "# likelihood\n",
    "logp = -.5 * tf.reduce_sum(m.z_placeholder**2)\n",
    "\n",
    "cost = 1*inside_cost - 1e6*outside_cost + 1 * logp # maximize inside cost and likelihood. minimize outside cost\n",
    "gradient = tf.gradients(cost, m.z_placeholder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grads = []\n",
    "latent_reps = [latent_rep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for _ in range(500):\n",
    "    grads.append(sess.run(gradient, get_feed_dict(latent_reps[-1]))[0])\n",
    "    step_size = .01 / np.linalg.norm(grads[-1][0])\n",
    "    latent_reps.append(latent_reps[-1] + step_size * grads[-1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exploration analysis\n",
    "latent_reps_np = np.array(latent_reps).reshape((len(latent_reps), -1))\n",
    "grads_np = np.array(grads).reshape((len(grads), -1))\n",
    "print_freq = int(len(grads) / 10) # when plotting changes over time, plot around 10 things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 6))\n",
    "\n",
    "plt.subplot(3, 2, 1)\n",
    "plt.plot(latent_reps_np.mean(axis=0))\n",
    "plt.xlabel('component position')\n",
    "plt.ylabel('latent rep (avg over steps)')\n",
    "\n",
    "plt.subplot(3, 2, 2)\n",
    "plt.plot(grads_np.mean(axis=0))\n",
    "plt.xlabel('component position')\n",
    "plt.ylabel('gradient (avg over steps)')\n",
    "\n",
    "plt.subplot(3, 2, 3)\n",
    "plt.plot([np.linalg.norm(l) for l in latent_reps])\n",
    "plt.xlabel('step')\n",
    "plt.ylabel('norm of latent representation')\n",
    "\n",
    "plt.subplot(3, 2, 4)\n",
    "plt.plot([np.linalg.norm(g) for g in grads])\n",
    "plt.xlabel('step')\n",
    "plt.ylabel('norm of gradient')\n",
    "\n",
    "plt.subplot(3, 2, 5)\n",
    "for i in range(0, len(latent_reps), print_freq):\n",
    "    plt.plot(latent_reps_np[i])\n",
    "plt.xlabel('component position')\n",
    "plt.ylabel('latent rep over time')\n",
    "\n",
    "plt.subplot(3, 2, 6)\n",
    "for i in range(0, len(grads), print_freq):\n",
    "    plt.plot(grads_np[i])\n",
    "plt.xlabel('component position')\n",
    "plt.ylabel('gradient over time')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.arange(100, len(latent_reps), 100) #[100, 300, 500, 1000]\n",
    "indices = [50, 100, 150, 200]\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, len(indices)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(np.linspace(0, 30000, 2**12), np.squeeze(reconstruction), color='k', label='0')\n",
    "for i in range(len(indices)):\n",
    "    plt.plot(np.linspace(0, 30000, 2**12), \n",
    "             np.squeeze(m.decode(latent_reps[indices[i]], intermediate_zs)),\n",
    "             color=colors[i], label=indices[i])\n",
    "plt.axvline(lambdas[0])\n",
    "plt.axvline(lambdas[-1])\n",
    "plt.xlabel('Wavelength $[\\AA]$')\n",
    "plt.ylabel('Normalized flux')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(lambdas, np.squeeze(reconstruction)[window[0]:window[1]], color='k', label='0')\n",
    "for i in range(len(indices)):\n",
    "    plt.plot(lambdas, \n",
    "             np.squeeze(m.decode(latent_reps[indices[i]], intermediate_zs))[window[0]:window[1]], \n",
    "             color=colors[i], label=indices[i])\n",
    "plt.xlabel('Wavelength $[\\AA]$')\n",
    "plt.ylabel('Normalized flux')\n",
    "#plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
