{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import corner\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import tftables\n",
    "import time\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import data_loader\n",
    "import model_short as model\n",
    "import toy_data_loader\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True, precision=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class hps:\n",
    "    pass\n",
    "hps.n_levels = 3 # number of splits\n",
    "hps.depth = 3 # number of layers in revnet\n",
    "hps.width = 16 # channels in revnet layers\n",
    "hps.polyak_epochs = 1\n",
    "hps.beta1 = .9 # learning rate annealing factor\n",
    "hps.weight_decay = 1 # learning rate annealing factor\n",
    "hps.lr = .001 # base learning rate\n",
    "hps.n_data = 100000 # number of input spectra\n",
    "hps.batch_size = 50 # number of spectra in a batch\n",
    "hps.n_batches = int(hps.n_data / hps.batch_size)\n",
    "hps.n_bins = 2**12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select real or toy data by uncommenting the appropriate line\n",
    "# real data must have n_data=8000, n_bins=40000\n",
    "#input_stream, initialize_input_stream, data_init = data_loader.create_data_loader(\n",
    "input_stream, initialize_input_stream, data_init = toy_data_loader.create_data_loader(\n",
    "    sess, hps.batch_size, hps.n_data, hps.n_bins\n",
    ")\n",
    "'''\n",
    "spectra = np.load('sample_short.npz')['spectra']\n",
    "sqrt = np.sqrt(spectra)\n",
    "\n",
    "# add noise\n",
    "#sums = spectra.sum(axis=1)\n",
    "#sqrtsums = sqrt.sum(axis=1)\n",
    "#As = .02 * sums / (np.sqrt(2 / 3.14) * sqrtsums)\n",
    "#noise = np.random.normal(scale=(np.repeat(As[:, np.newaxis], hps.n_bins, axis=1) * sqrt))\n",
    "#print((np.abs(noise).sum(axis=1) / spectra.sum(axis=1)))\n",
    "\n",
    "scaled_spectra = spectra / spectra.std(axis=1)[:, np.newaxis]\n",
    "#scaled_spectra = (spectra + noise) / (spectra + noise).std(axis=1)[:, np.newaxis]\n",
    "centered_spectra = scaled_spectra - scaled_spectra.mean(axis=1)[:, np.newaxis]\n",
    "#normalized_spectra = spectra / np.max(spectra, axis=1)[:, np.newaxis]\n",
    "\n",
    "def create_data_loader(sess, data, batch_size):\n",
    "    placeholder_data = tf.compat.v1.placeholder(tf.float32, data.shape)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(placeholder_data)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    iterator = dataset.make_initializable_iterator()\n",
    "    input_stream = iterator.get_next()\n",
    "    \n",
    "    def initialize_input_stream():\n",
    "        sess.run(iterator.initializer, feed_dict={placeholder_data: data})\n",
    "    \n",
    "    initialize_input_stream()\n",
    "    data_init = sess.run(input_stream)\n",
    "    return input_stream, initialize_input_stream, data_init\n",
    "\n",
    "input_stream, initialize_input_stream, data_init = create_data_loader(\n",
    "    sess, centered_spectra[:, :, np.newaxis], hps.batch_size\n",
    ")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(data_init.shape)\n",
    "plt.figure(figsize=(15, 5))\n",
    "for spectrum in data_init[:5]:\n",
    "    plt.plot(spectrum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with tf.device(\"/device:GPU:0\"):\n",
    "    m = model.model(sess, hps, input_stream, data_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_processed = 0\n",
    "training_results = []\n",
    "lrs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hps.epochs = 100\n",
    "hps.epochs_warmup = .01\n",
    "hps.lr = .0001\n",
    "\n",
    "for epoch in tqdm(range(1, hps.epochs + 1), desc='Epochs'):\n",
    "    epoch_results = []\n",
    "    initialize_input_stream()\n",
    "    with tqdm(total=hps.n_batches) as pbar:\n",
    "        for iteration in range(hps.n_batches):\n",
    "            pbar.set_description('Epoch ' + str(epoch))\n",
    "            lr = hps.lr * min(1., n_processed / (hps.batch_size * hps.n_batches * hps.epochs_warmup))\n",
    "            training_result = [m.train(lr)]\n",
    "            epoch_results += training_result\n",
    "            training_results += training_result\n",
    "            lrs += [lr]\n",
    "            n_processed += hps.batch_size\n",
    "            pbar.set_postfix(lr=lr, loss=np.mean(epoch_results))\n",
    "            pbar.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(np.linspace(0, len(training_results) / hps.n_batches, len(training_results)), training_results)\n",
    "#training_results_per_epoch = np.reshape(training_results, [-1, hps.n_batches]).mean(axis=1)\n",
    "#plt.plot(np.arange(0+hps.n_batches/2, len(training_results)+hps.n_batches/2, hps.n_batches), training_results_per_epoch)\n",
    "#plt.yscale('symlog')\n",
    "plt.ylim(-5, -4)\n",
    "plt.xlabel('epochs')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(np.linspace(0, len(training_results) / hps.n_batches, len(training_results)), lrs)\n",
    "plt.xlabel('epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i = np.random.randint(0, hps.batch_size)\n",
    "spectrum = data_init[i:i+1, :, :]\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "latent_rep = m.encode(spectrum)\n",
    "reconstruction = m.decode(latent_rep)\n",
    "print(latent_rep.mean(), latent_rep.std())\n",
    "print(reconstruction.mean(), reconstruction.std())\n",
    "print(np.mean((spectrum - reconstruction)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for channel in range(latent_rep.shape[-1]):\n",
    "    plt.plot(latent_rep[0, :, channel])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = (1850, 2200) #(12000, 14000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.plot(np.squeeze(reconstruction))\n",
    "plt.plot(np.squeeze(spectrum))\n",
    "plt.axvline(window[0])\n",
    "plt.axvline(window[1])\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.plot(range(*window), np.squeeze(reconstruction)[window[0]:window[1]])\n",
    "plt.plot(range(*window), np.squeeze(spectrum)[window[0]:window[1]])\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.plot(range(*window), np.squeeze(reconstruction - spectrum)[window[0]:window[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "latent_reps = np.empty([hps.n_batches, hps.batch_size, latent_rep.shape[1], latent_rep.shape[2]])\n",
    "initialize_input_stream()\n",
    "with tqdm(total=hps.n_batches) as pbar:\n",
    "    for i in range(hps.n_batches):\n",
    "        data = sess.run(input_stream)\n",
    "        latent_reps[i] = m.encode(data)\n",
    "        pbar.set_postfix(mean=latent_reps.mean(), std=latent_reps.std())\n",
    "        pbar.update()\n",
    "\n",
    "latent_reps = latent_reps.reshape(hps.n_data, latent_rep.shape[1], latent_rep.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(latent_reps.mean(axis=0)[:, 0])\n",
    "plt.plot(latent_reps.mean(axis=0)[:, 1])\n",
    "plt.plot(latent_reps.mean(axis=0)[:, 2])\n",
    "plt.plot(latent_reps.mean(axis=0)[:, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "components = 16\n",
    "start_position = int(latent_reps.shape[1] / 2 - components / 2)\n",
    "\n",
    "print(latent_reps.shape)\n",
    "print(latent_reps[:, start_position:start_position + components, 0].mean(axis=0))\n",
    "print(latent_reps[:, start_position:start_position + components, 0].std(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = corner.corner(latent_reps[:, start_position:start_position + components].sum(axis=2))\n",
    "\n",
    "axes = np.array(figure.axes).reshape((components, components))\n",
    "for yi in range(components):\n",
    "    for xi in range(yi):\n",
    "        ax = axes[yi, xi]\n",
    "        ax.axvline(0, color=\"g\")\n",
    "        ax.axhline(0, color=\"g\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_latent_rep = np.random.normal(size=latent_rep.shape)\n",
    "#sampled_latent_rep[0, :, 0] = latent_reps.mean(axis=0)[:, 0]\n",
    "#sampled_latent_rep[0, :, 1] = latent_reps.mean(axis=0)[:, 1]\n",
    "#sampled_latent_rep[0, :, 2] = latent_reps.mean(axis=0)[:, 2]\n",
    "#sampled_latent_rep[0, :, 3] = latent_reps.mean(axis=0)[:, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(sampled_latent_rep[0, :, 0])\n",
    "plt.plot(sampled_latent_rep[0, :, 1])\n",
    "plt.plot(sampled_latent_rep[0, :, 2])\n",
    "plt.plot(sampled_latent_rep[0, :, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.squeeze(m.decode(sampled_latent_rep)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "model_filename = 'models/model-{}'.format(datetime.now().strftime('%y%m%d-%H%M%S'))\n",
    "print(model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.save(model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.restore('models/model-200304-081901')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
