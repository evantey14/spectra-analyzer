{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import corner\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import tables\n",
    "\n",
    "from analysis_utils import *\n",
    "from data import data_loader, toy_data\n",
    "import glow as model\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('font', family='serif')\n",
    "plt.rc('xtick', labelsize=8)\n",
    "plt.rc('ytick', labelsize=8)\n",
    "plt.rc('axes', labelsize=8)\n",
    "plt.rc('figure', autolayout=True, dpi=300)\n",
    "plt.rc('lines', linewidth=1)\n",
    "plt.rc('legend', fontsize=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class hps:\n",
    "    pass\n",
    "hps.level_depths = [*[3]*3, *[3]*10] #[3, *[1]*11, 3] # array of length n_levels\n",
    "hps.n_levels = len(hps.level_depths) # number of splits\n",
    "hps.width = 16 # channels in revnet layers\n",
    "hps.window_size = 25 # conv window size in f()\n",
    "hps.n_data = 16000 # number of input spectra\n",
    "hps.batch_size = 50 # number of spectra in a batch\n",
    "hps.n_batches = int(hps.n_data / hps.batch_size)\n",
    "hps.n_bins = 2**15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.compat.v1.InteractiveSession()\n",
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_source = 'real'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_source == 'toy':\n",
    "    spectra, labels = toy_data.generate_spectra(hps.n_data, hps.n_bins)\n",
    "    labels = labels[:, 1:3] # ignore temperature and sigma (leaving A, mu)\n",
    "    input_stream, label_stream, initialize_stream = (\n",
    "        data_loader.create_loader_from_array(sess, hps.batch_size, spectra, labels)\n",
    "    )\n",
    "elif data_source == 'real':\n",
    "    '''input_stream, label_stream, initialize_stream = (\n",
    "        data_loader.create_loader_from_hdf5(sess, hps.batch_size, 'data/sample_short.h5')\n",
    "    )'''\n",
    "    file = np.load('data/sample_short.npz')\n",
    "    spectra, labels = file['spectra'], file['labels']\n",
    "    input_stream, label_stream, initialize_stream = (\n",
    "        data_loader.create_loader_from_array(sess, hps.batch_size, spectra, labels)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initialize_stream()\n",
    "spectra = sess.run(input_stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 2))\n",
    "for spectrum in spectra[:25]:\n",
    "    plt.plot(spectrum, alpha=.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with tf.device(\"/device:GPU:0\"):\n",
    "    m = model.model(sess, hps, input_stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.trainable_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_processed = 0\n",
    "training_results = []\n",
    "lrs = []\n",
    "prev_loss = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_level = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hps.epochs = 30\n",
    "hps.epochs_warmup = .01\n",
    "hps.lr = .001\n",
    "\n",
    "for epoch in tqdm(range(1, hps.epochs + 1), desc='Epochs'):\n",
    "    epoch_results = []\n",
    "    initialize_stream()\n",
    "    with tqdm(total=hps.n_batches) as pbar:\n",
    "        for iteration in range(hps.n_batches):\n",
    "            pbar.set_description('Epoch ' + str(epoch))\n",
    "            lr = hps.lr * min(1., n_processed / (hps.batch_size * hps.n_batches * hps.epochs_warmup))\n",
    "            training_result = [m.train(lr, training_level)]\n",
    "            epoch_results += training_result\n",
    "            training_results += training_result\n",
    "            lrs += [lr]\n",
    "            n_processed += hps.batch_size\n",
    "            pbar.set_postfix(lr=lr, loss=np.mean(epoch_results), training_level=training_level)\n",
    "            pbar.update()\n",
    "        current_loss = np.mean(epoch_results)\n",
    "        if (np.abs(prev_loss - current_loss) < .001) and training_level < hps.n_levels - 1:\n",
    "            training_level += 1\n",
    "        elif (np.abs(prev_loss - current_loss) < .001) and training_level == hps.n_levels - 1:\n",
    "            pass\n",
    "            #break\n",
    "        prev_loss = current_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hps.epochs = 15\n",
    "hps.epochs_warmup = .01\n",
    "hps.lr = .001\n",
    "\n",
    "for epoch in tqdm(range(1, hps.epochs + 1), desc='Epochs'):\n",
    "    epoch_results = []\n",
    "    initialize_stream()\n",
    "    with tqdm(total=hps.n_batches) as pbar:\n",
    "        for iteration in range(hps.n_batches):\n",
    "            pbar.set_description('Epoch ' + str(epoch))\n",
    "            lr = hps.lr * min(1., n_processed / (hps.batch_size * hps.n_batches * hps.epochs_warmup))\n",
    "            training_result = [m.train(lr)]\n",
    "            epoch_results += training_result\n",
    "            training_results += training_result\n",
    "            lrs += [lr]\n",
    "            n_processed += hps.batch_size\n",
    "            pbar.set_postfix(lr=lr, loss=np.mean(epoch_results))\n",
    "            pbar.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "\n",
    "epochs = np.linspace(0, len(training_results) / hps.n_batches, len(training_results))\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(epochs, training_results)\n",
    "plt.ylim(-7, 0)\n",
    "plt.xlabel('epochs')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(epochs, lrs)\n",
    "plt.xlabel('epochs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generate reconstructions of spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "i = np.random.randint(0, hps.batch_size)\n",
    "spectrum = spectra[i:i+1, :, :]\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_rep, intermediate_zs = m.encode(spectrum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SAMPLES_PER_INDEX = 10\n",
    "reconstructions = [] \n",
    "stats = []\n",
    "for zs_used in tqdm(range(len(intermediate_zs) + 1)):\n",
    "    index = len(intermediate_zs) - zs_used\n",
    "    reconstructions_i = [\n",
    "        m.decode(latent_rep, intermediate_zs[index:]) \n",
    "        for _ in range(SAMPLES_PER_INDEX)\n",
    "    ]\n",
    "    stats_i = [get_stats(spectrum, r) for r in reconstructions_i]\n",
    "    reconstructions.append(reconstructions_i)\n",
    "    stats.append(stats_i)\n",
    "reconstructions = np.array(reconstructions)\n",
    "stats = np.array(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = (0, hps.n_bins)\n",
    "#window = (int(hps.n_bins*.4), int(hps.n_bins*.6)) \n",
    "window = (12000, 14000)\n",
    "\n",
    "lambdas = np.arange(0, hps.n_bins) # remap bins to wavelengths here\n",
    "#lambdas = np.linspace(0, 30000, 2**12) # in angstrom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "\n",
    "zs_used = [0, 3, 6, 9, 12]\n",
    "reconstruction_labels = [\"d($\\widetilde{{h}}_{{{}}}$)\".format(i) for i in zs_used]\n",
    "residual_labels = [s + \"-x\" for s in reconstruction_labels]\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plot_window(lambdas, \n",
    "            [reconstructions[i][0] for i in zs_used],\n",
    "            window=window, labels=reconstruction_labels, alpha=.75)\n",
    "plot_window(lambdas, [spectrum], labels=[\"x\"], window=window)\n",
    "plt.xlabel('Wavelength $[\\AA]$')\n",
    "plt.ylabel(\"Normalized flux\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plot_window(lambdas, \n",
    "            [reconstructions[i][0] - spectrum for i in zs_used],\n",
    "            window=window, labels=residual_labels, alpha=.75)\n",
    "plt.axhline(0, color=\"k\")\n",
    "plt.xlabel('Wavelength $[\\AA]$')\n",
    "plt.ylabel(\"d(z)-x\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(3, 2))\n",
    "plt.xticks(range(13))\n",
    "plot_mean_w_error(stats[:, :, 0], label=\"L1\")\n",
    "plot_mean_w_error(stats[:, :, 1], label=\"L2\")\n",
    "plot_mean_w_error(stats[:, :, 2], label=\"L4\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# latent variable behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "latent_reps = np.empty([hps.n_batches, hps.batch_size, latent_rep.shape[1], latent_rep.shape[2]])\n",
    "initialize_stream()\n",
    "\n",
    "for i in tqdm(range(hps.n_batches)):\n",
    "    data = sess.run(input_stream)\n",
    "    latent_reps[i], _ = m.encode(data)\n",
    "\n",
    "latent_reps = latent_reps.reshape(hps.n_data, latent_rep.shape[1] * latent_rep.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(3, 1))\n",
    "plot_mean_w_error(latent_reps, axis=0)\n",
    "plt.axhline(0, color=\"k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4, 4))\n",
    "figure = corner.corner(latent_reps)\n",
    "\n",
    "axes = np.array(figure.axes).reshape((latent_reps.shape[1], latent_reps.shape[1]))\n",
    "for yi in range(latent_reps.shape[1]):\n",
    "    for xi in range(yi):\n",
    "        ax = axes[yi, xi]\n",
    "        ax.axvline(0, color=\"g\")\n",
    "        ax.axhline(0, color=\"g\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generate random realization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 2))\n",
    "N = 15\n",
    "random_latent_reps = [np.random.normal(size=latent_rep.shape) for _ in range(N)]\n",
    "plot_window(lambdas, [m.decode(z) for z in random_latent_reps], window=None, alpha=.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_test = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_source == 'toy':\n",
    "    test_spectra, test_labels = toy_data.generate_spectra(n_test, hps.n_bins)\n",
    "    test_labels = test_labels[:, 1:3] # ignore temperature and sigma (leaving A, mu)\n",
    "    test_input_stream, test_label_stream, initialize_test_stream = (\n",
    "        data_loader.create_loader_from_array(sess, n_test, test_spectra, test_labels)\n",
    "    )\n",
    "elif data_source == 'real':\n",
    "    test_input_stream, test_label_stream, initialize_test_stream = (\n",
    "        data_loader.create_loader_from_hdf5(sess, n_test, 'data/test_short.h5')\n",
    "    )\n",
    "initialize_test_stream()\n",
    "test_spectra, test_labels = sess.run([test_input_stream, test_label_stream])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_zs, test_intermediate_zs = m.encode(test_spectra)\n",
    "test_reconstructions = m.decode(test_zs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = []\n",
    "for zs_used in tqdm(range(len(intermediate_zs) + 1)):\n",
    "    index = len(intermediate_zs) - zs_used\n",
    "    test_reconstructions = m.decode(test_zs, test_intermediate_zs[index:])\n",
    "    stats_i = get_stats(test_spectra, test_reconstructions)\n",
    "    stats.append(stats_i)\n",
    "stats = np.array(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(3, 2))\n",
    "plt.xticks(range(13))\n",
    "plt.plot(stats[:, 0], label=\"L1\")\n",
    "plt.plot(stats[:, 1], label=\"L2\")\n",
    "plt.plot(stats[:, 2], label=\"L4\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "model_filename = 'models/model-{}'.format(datetime.now().strftime('%y%m%d-%H%M%S'))\n",
    "print(model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.save(model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.restore('models/model-200304-081901')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
