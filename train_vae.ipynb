{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from vae import VariationalAutoencoder\n",
    "from conv_vae import ConvolutionalVAE\n",
    "from data import toy_data\n",
    "from data import data_loader\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('font', family='serif')\n",
    "plt.rc('xtick', labelsize=8)\n",
    "plt.rc('ytick', labelsize=8)\n",
    "plt.rc('axes', labelsize=8)\n",
    "plt.rc('figure', autolayout=True, dpi=300)\n",
    "plt.rc('lines', linewidth=1)\n",
    "plt.rc('legend', fontsize=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.compat.v1.InteractiveSession()\n",
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 2**15 #1569128\n",
    "latent_rep_size = 40\n",
    "label_size = 2\n",
    "n_data = 16000 # if using hdf5 file, should be set to match file\n",
    "learning_rate = .001\n",
    "batch_size = 50\n",
    "\n",
    "network_architecture = {\n",
    "    'input_size': input_size,\n",
    "    'latent_representation_size': latent_rep_size,\n",
    "    'encoder_layer_sizes': [input_size, 100, 100, 90, 90, 80, 80, 2 * latent_rep_size],\n",
    "    'decoder_layer_sizes': [latent_rep_size, 80, 80, 90, 90, 100, 100, input_size],\n",
    "    'label_predictor_layer_sizes': [latent_rep_size, 40, 20, 20, 10, 10, 5, 5, label_size]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_source = 'real'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if data_source == 'toy':\n",
    "    spectra, labels = toy_data.generate_spectra(n_data, network_architecture['input_size'])\n",
    "    labels = labels[:, 1:3] # ignore temperature and sigma (leaving A, mu)\n",
    "    input_stream, label_stream, initialize_stream = (\n",
    "        data_loader.create_loader_from_array(sess, batch_size, spectra, labels)\n",
    "    )\n",
    "elif data_source == 'real':\n",
    "    input_stream, label_stream, initialize_stream = (\n",
    "        data_loader.create_loader_from_hdf5(sess, batch_size, 'data/sample_short.h5')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "vae = VariationalAutoencoder(sess, network_architecture, input_stream, label_stream, learning_rate, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_batches = int(n_data / batch_size)\n",
    "\n",
    "costs = []\n",
    "l1_costs = []\n",
    "l2_costs = []\n",
    "l_costs = []\n",
    "label_costs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_epochs = 5\n",
    "\n",
    "for epoch in tqdm(range(1, training_epochs + 1), desc='Epochs'):\n",
    "    initialize_stream()\n",
    "    with tqdm(total=total_batches) as pbar:\n",
    "        for batch in range(total_batches):\n",
    "            pbar.set_description('Epoch ' + str(epoch))\n",
    "            _, cost, l1_loss, r_cost, l_cost, _, m_cost = vae.optimize()\n",
    "\n",
    "            costs += [cost]\n",
    "            l1_costs += [l1_loss]\n",
    "            l2_costs += [r_cost]\n",
    "            l_costs += [l_cost]\n",
    "            label_costs += [m_cost]\n",
    "            \n",
    "            pbar.set_postfix(loss=cost, l1=l1_loss, l2=r_cost/input_size, l=l_cost, m=m_cost)\n",
    "            pbar.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = np.linspace(0, len(costs) // total_batches, len(costs))\n",
    "\n",
    "plt.figure(figsize=(4, 2))\n",
    "plt.plot(epochs, costs, label='Loss')\n",
    "plt.plot(epochs, l2_costs, label='Reconstruction Loss')\n",
    "plt.plot(epochs, l_costs, label='KL Divergence')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.xticks(np.arange(0, 51, 5))\n",
    "#plt.xlim(0, 50)\n",
    "\n",
    "plt.yscale('log')\n",
    "#plt.ylim(10**2, 10**4)\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initialize_stream()\n",
    "spectra = sess.run(input_stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = np.random.randint(0, batch_size)\n",
    "spectrum = spectra[i, :, 0]\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruction = vae.reconstruct(spectrum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = (0, input_size)\n",
    "#window = (12000, 14000)\n",
    "#window = (700000, 700000+2**15)\n",
    "current_lambda = 500\n",
    "lambdas = [500]\n",
    "for i in range(1, 1569128):\n",
    "    if current_lambda >= 500 and current_lambda <= 3000:\n",
    "        current_lambda += .1\n",
    "    elif current_lambda > 3000 and current_lambda <= 25000:\n",
    "        delta = current_lambda / 650000\n",
    "        current_lambda += delta\n",
    "    elif current_lambda > 25000 and current_lambda <= 55000:\n",
    "        delta = current_lambda / 250000\n",
    "        current_lambda += delta\n",
    "    lambdas.append(current_lambda)\n",
    "lambdas = lambdas[700000:700000 + 2**15]\n",
    "#lambdas = np.linspace(0, 30, 2**15)\n",
    "\n",
    "lambdas = lambdas[window[0]:window[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(lambdas, spectrum[window[0]:window[1]], label='x')\n",
    "plt.plot(lambdas, reconstruction[window[0]:window[1]], label='d(e(x))')\n",
    "\n",
    "plt.xlabel('Wavelength $[\\AA]$')\n",
    "plt.ylabel('Normalized flux')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(lambdas, (reconstruction - spectrum)[window[0]:window[1]])\n",
    "plt.xlabel('Wavelength $[\\AA]$')\n",
    "plt.ylabel('d(e(x)) - x')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = np.linspace(0, len(costs) // total_batches, len(costs))\n",
    "\n",
    "plt.figure(figsize=(4, 2))\n",
    "plt.plot(epochs, label_costs)\n",
    "#plt.plot(epochs, l2_costs, label='Reconstruction Loss')\n",
    "#plt.plot(epochs, l_costs, label='KL Divergence')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.xticks(np.arange(0, 51, 5))\n",
    "plt.xlim(0, 50)\n",
    "\n",
    "plt.ylabel('Squared Error')\n",
    "\n",
    "#plt.axhline(.5, color='k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# latent space exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = (0, input_size)\n",
    "#window = (12000, 14000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "for _ in range(5):\n",
    "    z = vae.encode(spectrum)\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(z)\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(vae.decode(z)[window[0]:window[1]])\n",
    "\n",
    "plt.plot(spectrum[window[0]:window[1]], alpha = .5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 2))\n",
    "for _ in range(5):\n",
    "    z = np.random.normal(size=40)\n",
    "    plt.plot(vae.decode(z)[window[0]:window[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 2))\n",
    "for i in range(5):\n",
    "    plt.plot(spectra[i], alpha=.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluate on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_stream, test_label_stream, initialize_test_stream = (\n",
    "        data_loader.create_loader_from_hdf5(sess, batch_size, 'data/test_short.h5')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "initialize_test_stream()\n",
    "test_l1s = []\n",
    "test_l2s = []\n",
    "test_l4s = []\n",
    "for i in range(1000 // 50):\n",
    "    test_batch = sess.run(test_stream).squeeze()\n",
    "    for test_spectrum in test_batch:\n",
    "        test_reconstructions = vae.reconstruct(test_spectrum)\n",
    "        test_l1s.append(np.mean(np.abs(test_reconstructions - test_spectrum)))\n",
    "        test_l2s.append(np.mean((test_reconstructions - test_spectrum)**2))\n",
    "        test_l4s.append(np.mean((test_reconstructions - test_spectrum)**4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(test_l1s))\n",
    "print(np.mean(test_l2s)**.5)\n",
    "print(np.mean(test_l4s)**.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile_name = 'output/output-{}'.format(datetime.now().strftime('%y%m%d-%H%M%S'))\n",
    "vae.save(outfile_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.restore('output/output-200505-215641')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vae.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
